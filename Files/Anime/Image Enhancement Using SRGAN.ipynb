{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LTYlk-tvJOCk",
   "metadata": {
    "id": "LTYlk-tvJOCk"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30015bb",
   "metadata": {
    "id": "e30015bb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8745138",
   "metadata": {
    "id": "a8745138"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "with tf.device(device_name):\n",
    "    print(device_name.split(\":\")[1],\" running . . . \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832bae2f",
   "metadata": {
    "id": "832bae2f"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "import os, keras, numpy,tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "from numpy.random import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.layers import add\n",
    "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde13e23",
   "metadata": {
    "id": "bde13e23"
   },
   "outputs": [],
   "source": [
    "def Discriminator(input_shape_in = (16, 16, 3), target_shape_in = (128, 128, 3)):\n",
    "    \n",
    "    # input\n",
    "    input_shape = Input(shape = input_shape_in)\n",
    "    input_target = Input(shape = target_shape_in)\n",
    "    \n",
    "    # C64\n",
    "    model = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(input_target)\n",
    "    model = LeakyReLU(alpha=0.2)(model) # --> (64, 64)\n",
    "    \n",
    "    # C128\n",
    "    model = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)  # --> (32, 32)\n",
    "    \n",
    "    # C256\n",
    "    model = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)  # --> (16, 16)\n",
    "\n",
    "    model = Concatenate()([model, input_shape])\n",
    "    \n",
    "    # C256\n",
    "    model = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)  # --> (8, 8)\n",
    "\n",
    "    # C512\n",
    "    model = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)  # --> (4, 4)\n",
    "    \n",
    "    # second last output layer\n",
    "    model = Conv2D(128, (4,4), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU(alpha=0.2)(model)  # --> (4, 4)\n",
    "    \n",
    "    # patch output\n",
    "    model = Conv2D(1, (4,4), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(model)\n",
    "    model = Activation('sigmoid')(model)  # --> (4, 4)\n",
    "    \n",
    "    # define model\n",
    "    discriminator_model = Model(inputs = [input_shape, input_target], outputs = model)\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0005, beta_1=0.5)\n",
    "    discriminator_model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "        \n",
    "    return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470acffc",
   "metadata": {
    "id": "470acffc"
   },
   "outputs": [],
   "source": [
    "a = Discriminator()\n",
    "print(a.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2769a",
   "metadata": {
    "id": "fcd2769a"
   },
   "outputs": [],
   "source": [
    "# plot the discriminator model\n",
    "tf.keras.utils.plot_model(a,show_shapes=True,\n",
    "                          show_dtype=True,\n",
    "                          show_layer_names=True,\n",
    "                          show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef3b46",
   "metadata": {
    "id": "edef3b46"
   },
   "outputs": [],
   "source": [
    "# define an encoder block\n",
    "def encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(layer_in)\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494fafc5",
   "metadata": {
    "id": "494fafc5"
   },
   "outputs": [],
   "source": [
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(layer_in)\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    if dropout:\n",
    "        g = Dropout(0.5)(g, training=True)\n",
    "    g = Concatenate()([g, skip_in])\n",
    "    g = Activation('relu')(g)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85eb7b",
   "metadata": {
    "id": "9e85eb7b"
   },
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def Generator(image_shape=(16,16,3), latent_dim = 512):\n",
    "   \n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)  # --> (16, 16)\n",
    "\n",
    "    input_latent = Input(shape=(latent_dim,))\n",
    "    input_img_1 = Dense(128*128*3)(input_latent)\n",
    "    input_img_1 = Reshape((128, 128, 3))(input_img_1)  # --> (128, 128)\n",
    "    \n",
    "    # encoder model\n",
    "    e1 = encoder_block(input_img_1, 64, batchnorm=False)  # --> (64, 64)\n",
    "    e2 = encoder_block(e1, 64)   # --> (32, 32)\n",
    "    e3 = encoder_block(e2, 64)   # --> (16, 16)\n",
    "    e3 = Concatenate()([e3, in_image])  # --> (16, 16)\n",
    "    e4 = encoder_block(e3, 128)   # --> (8, 8)\n",
    "    e5 = encoder_block(e4, 128)   # --> (4, 4)\n",
    "    e6 = encoder_block(e5, 512)   # --> (2, 2)\n",
    "    \n",
    "    # bottleneck, no batch norm and relu\n",
    "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(e6)\n",
    "    b = Activation('relu')(b)   # --> (1, 1)\n",
    "    \n",
    "    # decoder model\n",
    "    d2 = decoder_block(b, e6, 512)    # --> (2, 2)\n",
    "    d3 = decoder_block(d2, e5, 128)   # --> (4, 4)\n",
    "    d4 = decoder_block(d3, e4, 128)   # --> (8, 8)\n",
    "    d5 = decoder_block(d4, e3, 64, dropout=False)   # --> (16, 16)\n",
    "    d5 = Concatenate()([d5, in_image])\n",
    "    d6 = decoder_block(d5, e2, 64, dropout=False)   # --> (32, 32)\n",
    "    d7 = decoder_block(d6, e1, 64, dropout=False)    # --> (64, 64)\n",
    "    \n",
    "    # output\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(d7)\n",
    "    for _ in range(2):\n",
    "      g = Conv2D(3, (2,2), padding='same', kernel_initializer=RandomNormal(stddev=0.02))(g)\n",
    "      g = BatchNormalization()(g)\n",
    "      g = Activation(\"relu\")(g)\n",
    "    out_image = Activation('tanh')(g)  # --> (128, 128)\n",
    "    \n",
    "    # model\n",
    "    model = Model([in_image, input_latent], out_image)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c76602",
   "metadata": {
    "id": "f0c76602"
   },
   "outputs": [],
   "source": [
    "b = Generator()\n",
    "print(b.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c11ce",
   "metadata": {
    "id": "a06c11ce"
   },
   "outputs": [],
   "source": [
    "# plot the discriminator model\n",
    "tf.keras.utils.plot_model(b,show_shapes=True,\n",
    "                          show_dtype=True,\n",
    "                          show_layer_names=True,\n",
    "                          show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c11b8",
   "metadata": {
    "id": "5c4c11b8"
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def GAN(g_model, d_model, image_shape = (16, 16, 3), latent_dim = 512):\n",
    "    \n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    \n",
    "   \n",
    "    in_src = Input(shape=image_shape)\n",
    "    latent_input = Input(shape=(latent_dim,))\n",
    "   \n",
    "    gen_out = g_model([in_src, latent_input])\n",
    "    \n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    \n",
    "    model = Model([in_src, latent_input], [dis_out, gen_out])\n",
    "    \n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99a70c",
   "metadata": {
    "id": "ed99a70c"
   },
   "outputs": [],
   "source": [
    "c = GAN(b, a)\n",
    "print(c.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91897689",
   "metadata": {
    "id": "91897689"
   },
   "outputs": [],
   "source": [
    "# plot the discriminator model\n",
    "tf.keras.utils.plot_model(c,show_shapes=True,\n",
    "                          show_dtype=True,\n",
    "                          show_layer_names=True,\n",
    "                          show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a35054",
   "metadata": {
    "id": "f6a35054"
   },
   "outputs": [],
   "source": [
    "def show_prediction(bw_images, rgb_images, predicted_rgb, epoch, n, save=False):\n",
    "    \n",
    "  plt.rcParams[\"figure.figsize\"] = (9,9)\n",
    "  for i in range(n):\n",
    "    plt.suptitle(\"Epoch_\"+str(epoch),size=16)\n",
    "      \n",
    "    plt.subplot(331)\n",
    "    plt.imshow(bw_images[i], cmap='gray')\n",
    "    plt.title(\"LR RGB Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(332)\n",
    "    plt.imshow(rgb_images[i])\n",
    "    plt.title(\"Original RGB Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(333)\n",
    "    plt.imshow(predicted_rgb[i])\n",
    "    plt.title(\"SR RGB Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    if(save==True):\n",
    "      plt.savefig(\"/content/drive/MyDrive/SRGAN/Model 16 Two/Predicted Outputs/Epoch_\"+str(epoch))\n",
    "    \n",
    "    # plt.show()\n",
    "    \n",
    "# plot data\n",
    "# save_plot(k[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97a1bd",
   "metadata": {
    "id": "da97a1bd"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = np.load(\"/content/drive/MyDrive/SRGAN/Dataset/Anime_rgb_resized_16_128_20000.npz\")\n",
    "    rgb, bw = data['a'], data['b']\n",
    "    rgb, bw = np.array(rgb), np.array(bw)\n",
    "    rgb, bw = rgb.astype('float32'), bw.astype('float32')\n",
    "    rgb = rgb.reshape((rgb.shape[0], rgb.shape[1], rgb.shape[2], 3))\n",
    "    bw = bw.reshape((bw.shape[0], bw.shape[1], bw.shape[2], 3))\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    rgb = (rgb - 127.5) / 127.5\n",
    "    bw = (bw - 127.5) / 127.5\n",
    "    return rgb, bw\n",
    "    \n",
    "# rgb, bw = load_data()\n",
    "# print(rgb.shape, bw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883c301",
   "metadata": {
    "id": "a883c301"
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(rgb_images, bw_images, n_samples, patch_size):\n",
    "    ix = randint(0, rgb_images.shape[0], n_samples)\n",
    "    rgb_images = rgb_images[ix]\n",
    "    bw_images = bw_images[ix]\n",
    "    y = ones((n_samples, patch_size, patch_size, 1))\n",
    "    return [bw_images, rgb_images], y\n",
    "\n",
    "# d = generate_real_samples(rgb, bw, 32, 8)\n",
    "# print(np.array(d[0][0]).shape, np.array(d[0][1]).shape, np.array(d[1]).shape)\n",
    "# d[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b981902",
   "metadata": {
    "id": "8b981902"
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, bw_images, n_samples, patch_size, latent_dim=512):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    pred_rgb_images = generator.predict([bw_images, z_input])\n",
    "    y = zeros((n_samples, patch_size, patch_size, 1))\n",
    "    return pred_rgb_images, z_input, y\n",
    "\n",
    "# with tf.device(device_name):\n",
    "# kh = generate_fake_samples(b, 512, 3)\n",
    "# print(\"shape of the generated images: \",kh[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86702d",
   "metadata": {
    "id": "5b86702d"
   },
   "outputs": [],
   "source": [
    "def summarize_the_model(generator, rgb_images, bw_images, epoch, latent_dim = 512, n_samples=1, save=False):\n",
    "    kk = 12310\n",
    "    bw_images = bw_images[kk]\n",
    "    bw_images = bw_images.reshape((1, bw_images.shape[0], bw_images.shape[1], 3))\n",
    "    rgb_images = rgb_images[kk]\n",
    "    rgb_images = rgb_images.reshape((1, rgb_images.shape[0], rgb_images.shape[1], 3))\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    predicted_rgb  = generator.predict([bw_images, z_input])\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    # X = (X + 1) / 2.0\n",
    "    bw_images = (bw_images + 1.0) / 2.0\n",
    "    rgb_images = (rgb_images + 1.0) / 2.0\n",
    "    predicted_rgb = (predicted_rgb + 1.0) / 2.0\n",
    "    show_prediction(bw_images, rgb_images, predicted_rgb, epoch, n=n_samples, save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef034d",
   "metadata": {
    "id": "a7ef034d"
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, n_epochs=3, n_batch=128):\n",
    "    \n",
    "    rgb_images, bw_images = dataset\n",
    "    \n",
    "    print(\"Data Size: \",rgb_images.shape)\n",
    "    print(\"No. Of Epoch: \",n_epochs)\n",
    "    bat_per_epo = int(rgb_images.shape[0] / n_batch)\n",
    "    print(\"Batch Per Epoch: \", bat_per_epo)\n",
    "    print(\"Full Batch: \",n_batch)\n",
    "    print(\"*\"*50,'\\n\\n')\n",
    "    \n",
    "    patch_size = d_model.output_shape[1]\n",
    "\n",
    "    d_loss_real_array,d_loss_fake_array =[],[]\n",
    "    g_loss_array = []\n",
    "    for i in range(n_epochs):\n",
    "        d_loss_r,d_loss_f = 0.0,0.0\n",
    "        g_loss = 0.0\n",
    "        \n",
    "        for j in range(bat_per_epo):\n",
    "\n",
    "            [bw_real, rgb_real], y_real = generate_real_samples(rgb_images, bw_images, n_batch, patch_size)\n",
    "            d_loss1  = d_model.train_on_batch([bw_real, rgb_real], y_real)\n",
    "            d_loss_r += d_loss1\n",
    "            # print(\"real_loss\")\n",
    "\n",
    "            pred_rgb, z_input, y_fake = generate_fake_samples(g_model, bw_real, n_batch, patch_size) # Trick 1 is Here\n",
    "            d_loss2  = d_model.train_on_batch([bw_real, pred_rgb], y_fake)\n",
    "            d_loss_f += d_loss2\n",
    "            # print(\"fake_loss\")\n",
    "\n",
    "            g_loss_1, _ , _ = gan_model.train_on_batch([bw_real, z_input], [y_real, rgb_real]) # Trick 2 is Here\n",
    "            g_loss += g_loss_1\n",
    "            # print(\"gan_loss\")\n",
    "\n",
    "        d_loss_real_array.append(d_loss_r)\n",
    "        d_loss_fake_array.append(d_loss_f)\n",
    "        g_loss_array.append(g_loss)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print('epoch -> [%d/%d], discriminator_loss_for_real_data = %.2f, discriminator_loss_for_fake_data = %.2f, generator_loss = %.2f\\n' %(i+1, n_epochs, d_loss_r, d_loss_f, g_loss))\n",
    "        epoch_k = i + 1\n",
    "        # if(epoch_k%30==0):\n",
    "        summarize_the_model(g_model, rgb_images, bw_images, epoch_k, n_samples = 1, save=True)\n",
    "        # g_model.save(\"g_gan_model_\"+str(i)+\".h5\")\n",
    "        g_model.save(\"/content/drive/MyDrive/SRGAN/Model 16 Two/SRGAN_Generator_Model.h5\")\n",
    "        d_model.save(\"/content/drive/MyDrive/SRGAN/Model 16 Two/SRGAN_Discriminator_Model.h5\")\n",
    "        gan_model.save(\"/content/drive/MyDrive/SRGAN/Model 16 Two/SRGAN_GAN_Model.h5\")\n",
    "        np.savez_compressed(\"/content/drive/MyDrive/SRGAN/Model 16 Two/SRGAN_Loss_Record.npz\", a=d_loss_real_array, b=d_loss_fake_array, c=g_loss_array)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return d_loss_real_array, d_loss_fake_array, g_loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347270c",
   "metadata": {
    "id": "6347270c"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):\n",
    "\n",
    "    n_epochs = 1500\n",
    "    n_batch = 128\n",
    "    \n",
    "    d_model = Discriminator()\n",
    "    g_model = Generator()\n",
    "    gan_model = GAN(g_model, d_model)\n",
    "    \n",
    "    dataset = load_data()\n",
    "    print('\\nREADY TO GO !!!\\n')\n",
    "\n",
    "    d_loss_real_array, d_loss_fake_array, g_loss_array = train(g_model, d_model, gan_model, dataset, n_epochs, n_batch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
